<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Document</title>
</head>
<body>
    <script>
       // 获取 MediaStream 对象
navigator.mediaDevices.getUserMedia({ audio: true })
  .then((stream) => {
    const audioContext = new AudioContext();
    const audioTracks = stream.getAudioTracks();

    // 创建 MediaStreamAudioSourceNode
    const sourceNode = audioContext.createMediaStreamSource(stream);

    // 创建 AnalyserNode
    const analyserNode = audioContext.createAnalyser();
    analyserNode.fftSize = 2048; // 设置 FFT 大小

    // 连接源节点和分析节点
    sourceNode.connect(analyserNode);

    // 获取音频数据
    const bufferLength = analyserNode.frequencyBinCount;
    const dataArray = new Uint8Array(bufferLength);

    // 创建 Canvas 元素
    const canvas = document.createElement('canvas');
    const canvasCtx = canvas.getContext('2d');
    document.body.appendChild(canvas);

    // 设置 Canvas 尺寸
    canvas.width = window.innerWidth/10;
    canvas.height = window.innerHeight/10;

    function drawVolume() {
      // 将当前音频数据复制到 dataArray 数组
      analyserNode.getByteTimeDomainData(dataArray);

      // 清空 Canvas
      canvasCtx.clearRect(0, 0, canvas.width, canvas.height);

      // 计算音量
      let volume = 0;
      for (let i = 0; i < bufferLength; i++) {
        volume += Math.abs((dataArray[i] - 128) / 128);
      }
      volume /= bufferLength;
      // 绘制音量图形
      const barWidth = canvas.width / 2;
      const barHeight = canvas.height * volume*10;
      canvasCtx.fillStyle = 'red';
      canvasCtx.fillRect(0, canvas.height - barHeight, barWidth, barHeight);

      // 通过 requestAnimationFrame 实现持续绘制
      requestAnimationFrame(drawVolume);
    }

    // 开始绘制音量
    drawVolume();

  })
  .catch((error) => {
    console.error('获取媒体流失败:', error);
  });


    </script>
</body>
</html>